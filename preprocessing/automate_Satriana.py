# -*- coding: utf-8 -*-
"""automate_Satriana.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dLWC1Cw-JrIphH_mwpP3PRY1Q7Mu-DFi

# **Otomatisasi proses preprocessing**

Dataset : Student Performance in Exams

**1. Import Library**
"""

# import libabry yang diperlukan

import pandas as pd
import numpy as np
import os
import argparse
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split

# Membuat fungsi utama untuk otomatisasi preprocessing dataset

def preprocess_students_data(input_path, output_path, target_mode='binned'):
  """
  Fungsi ini digunakan untuk melakukan preprocessing data pada dataset student performance.

  Tahapan preprocessing yang dilakukan:
  1. Membaca data dari file CSV.
  2. Menangani missing value.
  3. Menghapus data duplikat
  4. Deteksi dan penanganan outlier
  5. Melakukan normalisasi data menggunakan StandardScaler.
  6. Membuat kolom rata-rata (average score)
  7. Melakukan encoding pada kolom kategorical.
  8. Binning (pengelompokkan data)
  9. Split dataset menjadi data train dan test.
  10. Simpan hasil preprocessing ke dalam file CSV.

  """

  # 1. Membaca dataset
  print("1. Membaca dataset")
  df = pd.read_csv(input_path)
  print("Jumlah data awal: ", df.shape)

  # 2. Menangani missing value
  print("2. Menangani missing value")
  if df.isnull().values.any():
    print("Terdapat missing value")
    df = df.dropna()
    print("Jumlah data setelah dihapus missing value: ", df.shape)
  else:
    print("Tidak terdapat missing value")

  # 3 Menghapus data duplikat
  print("3. Menghapus data duplikat")
  df.drop_duplicates(inplace=True)
  print(f"Jumlah data setelah dihapus duplikat: {df.shape}")

  # Kolom numerikal
  numerical_cols = ['math score', 'reading score', 'writing score']

  # 4. Deteksi dan penanganan outlier
  print("4. Deteksi dan penanganan outlier")
  z_scores = np.abs((df[numerical_cols] - df[numerical_cols].mean()) / df[numerical_cols].std())
  df = df[(z_scores < 3).all(axis=1)]
  print("Jumlah data setelah dihapus outlier: ", df.shape)

  
  # 5. Melakukan normalisasi data menggunakan StandardScaler.
  print("5. Melakukan normalisasi data")
  scaler = StandardScaler()
  df[numerical_cols] = scaler.fit_transform(df[numerical_cols])
  print("Normalisasi selesai")

  
  # 6. Membuat kolom rata-rata (average score)
  print("6. Membuat kolom rata-rata (average score)")
  df['average_score'] = df[['math score', 'reading score', 'writing score']].mean(axis=1)

  # 7. Melakukan encoding pada kolom kategorikal
  print("7. Melakukan encoding pada kolom kategorikal")
  label_cols = ['gender', 'race/ethnicity', 'parental level of education',
                'lunch', 'test preparation course']
  le = LabelEncoder()
  for col in label_cols:
    df[col] = le.fit_transform(df[col])
  print("Encoding selesai")

  # 8. Binning (pengelompokkan data)
  print("8. Binning (pengelompokkan data)")
  bins = [-np.inf, -0.5, 0.5, np.inf]
  labels = ['low', 'medium', 'high']
  df['average_score_binned'] = pd.cut(df['average_score'], bins=bins, labels=labels)
  print("Binning selesai")

  # 9. Split dataset menjadi data train dan test.
  print("9. Split dataset menjadi data train dan test")
  if target_mode == 'binned':
      y = df['average_score_binned']
      X = df.drop(['average_score', 'average_score_binned'], axis=1)
  else:
      y = df['average_score']
      X = df.drop(['average_score_binned'], axis=1)

  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
  print("Data train shape: ", X_train.shape)
  print("Data test shape: ", X_test.shape)  
  
  # 10. Simpan hasil preprocessing ke dalam file CSV.
  print("10. Simpan hasil preprocessing ke dalam file CSV")
  df.to_csv(output_path, index=False)
  print(f"Preprocessing tersimpan di : {output_path}")

  return {
      'df': df,
      'X_train': X_train,
      'X_test': X_test,
      'y_train': y_train,
      'y_test': y_test
  }

# Contoh penggunaan fungsi preprocess_students_data
if __name__ == "__main__":

    # --- Tambahan opsional: parsing argumen (supaya bisa diubah lewat GitHub Actions) ---
    parser = argparse.ArgumentParser(
       description="Automated preprocessing for Student Performance dataset."
    )

    parser.add_argument(
       "--input_path", 
       default="studentsperformance_raw/StudentsPerformance.csv", 
       help="Path ke dataset asli (raw)."
    )

    parser.add_argument(
       "--output_path", 
       default="preprocessing/studentsperformance_preprocessing/StudentsPerformance_preprocessing.csv", 
       help="Path untuk menyimpan hasil preprocessing."
    )

    parser.add_argument(
       "--target_mode", 
       choices=["binned", "average"],
       default="binned", 
       help="Mode target: 'binned' untuk klasifikasi, 'average' untuk regresi."
    )

    args = parser.parse_args()

    # Jalankan fungsi utama preprocessing
    results = preprocess_students_data(
       input_path=args.input_path,
       output_path=args.output_path,
       target_mode=args.target_mode  # 'binned' atau 'average'
    )

    # Print ringkasan hasil
    print("âœ… Data preprocessing selesai.")
    print("ðŸ“Š Bentuk DataFrame akhir:", results['df'].shape)
    print("ðŸš‚ Mode Target:", args.target_mode)
    print("ðŸ’¾ Hasil preprocessing tersimpan di:", args.output_path)

